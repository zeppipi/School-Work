{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "monetary-anthropology",
   "metadata": {},
   "source": [
    "## FIT1043 Introduction to Data Science\n",
    "## Assignment 2 \n",
    "\n",
    "Hazael Frans Christian  \n",
    "32134835  \n",
    "30rd April 2021  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-commodity",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This assignment will be about grading essays, the csvs will include around 1000+ essays with their features and a final score and another csv with 200 essays with their features but no final score. The score goes from 1 to 6 and, the goal is to find a way to split the 1000+ essays 6 ways and accurately give their score, and by doing that, can give the score prediction to the 200 other essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opposite-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "welsh-chile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1457</td>\n",
       "      <td>2153</td>\n",
       "      <td>426</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.053991</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>26.625000</td>\n",
       "      <td>423.995272</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>207</td>\n",
       "      <td>0.485915</td>\n",
       "      <td>105</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>424</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503</td>\n",
       "      <td>1480</td>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.068493</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>26.545455</td>\n",
       "      <td>290.993103</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>148</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>77</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>356</td>\n",
       "      <td>345</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253</td>\n",
       "      <td>3964</td>\n",
       "      <td>849</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4.669022</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>17.326531</td>\n",
       "      <td>843.990544</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>285</td>\n",
       "      <td>0.335689</td>\n",
       "      <td>130</td>\n",
       "      <td>0.153121</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>988</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.704762</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>207.653784</td>\n",
       "      <td>0.988828</td>\n",
       "      <td>112</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1450</td>\n",
       "      <td>3139</td>\n",
       "      <td>600</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.231667</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>594.652150</td>\n",
       "      <td>0.991087</td>\n",
       "      <td>255</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>165</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>702</td>\n",
       "      <td>677</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1151</td>\n",
       "      <td>2404</td>\n",
       "      <td>467</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5.147752</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21.227273</td>\n",
       "      <td>462.987069</td>\n",
       "      <td>0.991407</td>\n",
       "      <td>200</td>\n",
       "      <td>0.428266</td>\n",
       "      <td>113</td>\n",
       "      <td>0.241970</td>\n",
       "      <td>529</td>\n",
       "      <td>519</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1015</td>\n",
       "      <td>1182</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4.904564</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>238.655462</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>94</td>\n",
       "      <td>0.390041</td>\n",
       "      <td>67</td>\n",
       "      <td>0.278008</td>\n",
       "      <td>293</td>\n",
       "      <td>283</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1345</td>\n",
       "      <td>1814</td>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.997245</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>27.923077</td>\n",
       "      <td>362.329640</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>170</td>\n",
       "      <td>0.468320</td>\n",
       "      <td>107</td>\n",
       "      <td>0.294766</td>\n",
       "      <td>427</td>\n",
       "      <td>415</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>344</td>\n",
       "      <td>1427</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.972125</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>22.076923</td>\n",
       "      <td>284.657277</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>144</td>\n",
       "      <td>0.501742</td>\n",
       "      <td>83</td>\n",
       "      <td>0.289199</td>\n",
       "      <td>323</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1077</td>\n",
       "      <td>2806</td>\n",
       "      <td>542</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.177122</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>24.636364</td>\n",
       "      <td>538.988889</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>284</td>\n",
       "      <td>0.523985</td>\n",
       "      <td>155</td>\n",
       "      <td>0.285978</td>\n",
       "      <td>596</td>\n",
       "      <td>575</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1332 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "0        1457   2153    426      14            6             0   \n",
       "1         503   1480    292       9            7             0   \n",
       "2         253   3964    849      19           26             1   \n",
       "3         107    988    210       8            7             0   \n",
       "4        1450   3139    600      13            8             0   \n",
       "...       ...    ...    ...     ...          ...           ...   \n",
       "1327     1151   2404    467      16           10             0   \n",
       "1328     1015   1182    241       0           14             0   \n",
       "1329     1345   1814    363       5           11             0   \n",
       "1330      344   1427    287       5            8             0   \n",
       "1331     1077   2806    542      24            6             0   \n",
       "\n",
       "      avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "0            5.053991         16          0          26.625000  423.995272   \n",
       "1            5.068493         11          0          26.545455  290.993103   \n",
       "2            4.669022         49          2          17.326531  843.990544   \n",
       "3            4.704762         12          0          17.500000  207.653784   \n",
       "4            5.231667         24          1          25.000000  594.652150   \n",
       "...               ...        ...        ...                ...         ...   \n",
       "1327         5.147752         22          0          21.227273  462.987069   \n",
       "1328         4.904564         16          0          15.062500  238.655462   \n",
       "1329         4.997245         13          3          27.923077  362.329640   \n",
       "1330         4.972125         13          1          22.076923  284.657277   \n",
       "1331         5.177122         22          3          24.636364  538.988889   \n",
       "\n",
       "      POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0            0.995294           207                  0.485915            105   \n",
       "1            0.996552           148                  0.506849             77   \n",
       "2            0.994100           285                  0.335689            130   \n",
       "3            0.988828           112                  0.533333             62   \n",
       "4            0.991087           255                  0.425000            165   \n",
       "...               ...           ...                       ...            ...   \n",
       "1327         0.991407           200                  0.428266            113   \n",
       "1328         0.990272            94                  0.390041             67   \n",
       "1329         0.998153           170                  0.468320            107   \n",
       "1330         0.991837           144                  0.501742             83   \n",
       "1331         0.994444           284                  0.523985            155   \n",
       "\n",
       "      synonym_words/total_words  unstemmed  stemmed  score  \n",
       "0                      0.246479        424      412      4  \n",
       "1                      0.263699        356      345      4  \n",
       "2                      0.153121        750      750      4  \n",
       "3                      0.295238        217      209      3  \n",
       "4                      0.275000        702      677      4  \n",
       "...                         ...        ...      ...    ...  \n",
       "1327                   0.241970        529      519      4  \n",
       "1328                   0.278008        293      283      3  \n",
       "1329                   0.294766        427      415      3  \n",
       "1330                   0.289199        323      312      3  \n",
       "1331                   0.285978        596      575      4  \n",
       "\n",
       "[1332 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.read_csv('FIT1043-Essay-Features.csv')\n",
    "submission = pd.read_csv('FIT1043-Essay-Features-Submission.csv')\n",
    "\n",
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-night",
   "metadata": {},
   "source": [
    "Import the neseccary libraries and the neseccary csvs\n",
    "\n",
    "the full_data csv includes the 1000+ essays with the score included while the submission csv includes the 200 essays with no score. The task here is to fill out the scores for the 200 essays in the submissions csv using the data in the full_data csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-cathedral",
   "metadata": {},
   "source": [
    "### Supervised Learning\n",
    "\n",
    "Supervised machine learning is when the algorithm is used to predict the output from an input data. For supervised learning, the input data it recieves are all labelled, which means the data has been tagged or given a class, for example, giving an image of a car and nothing else will be considered as unlabelled data, but giving an image of a car that has been tagged as a car, that will be considered as labelled data.\n",
    "\n",
    "When making a model, we will need some training data, the training data is data where the algorithm knows both the input and the output and uses this to make the model, the algorithm's prediction if it comes across data with an unknown output. When the model is finished, it will be tested with the test data or also known as the validation data, the test data is data where the output is unknown to the model but known to the person testing it, the model will give their predictions and be compared to the test data's actual output to check how accurate the model is right now currently, if the results are not good enough, it will be sent back to the training data where the model will be tweak until it gives a satisfying result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "diagnostic-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = full_data.drop(columns = ['score'])\n",
    "#label = full_data.drop(columns = ['essayid', 'chars', 'words', 'commas', 'apostrophes', 'punctuations', 'avg_word_length', 'sentences', 'questions', 'avg_word_sentence', 'POS', 'POS/total_words', 'prompt_words', 'prompt_words/total_words', 'synonym_words', 'synonym_words/total_words', 'unstemmed', 'stemmed'])\n",
    "\n",
    "features = full_data.iloc[:, [0,17]].values\n",
    "label = full_data.iloc[:, 18].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-april",
   "metadata": {},
   "source": [
    "For the 1000+ essays in the full_data csv, it has two parts, one is the features and the other is the label. The features of the essays includes everything like the essayid, their word count, how many prompt words they use, how many commas it has, and etc. But the features does not feature the score, since the score is the label for all of the essays. So, the full_data csv's column will be split into two parts, one including all of the features and the other including all of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "solved-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_validate, label_train, label_validate = train_test_split(features,label, test_size = 0.2, random_state = 0)\n",
    "#test size 20% and train size is 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-liver",
   "metadata": {},
   "source": [
    "As mentioned before, we will need some training data and test data which we can get both from the full_data csv. By simply cutting the csv's rows in two parts, we will now have a training data and test data. We can do that by using the 'train_test_split' function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-headset",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Classification in Machine Learning can come in binary or multi-class. A binary classification is a task of classifying elements to only two class, it is named binary, because just like binary, a classification with only 2 classes will only have 2 states. While dealing with more than 2 classes will create a multi-class classification.\n",
    "\n",
    "Our assignment has 6 different labels, a score that goes from 1 to 6, which means these essays will be split into 6 different classes, which means this assignment will be using a multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-symphony",
   "metadata": {},
   "source": [
    "We will be using the the Support Vector Machine (SVM) algorithm for this assignment and in preperation on using said algorithm, we will need to normalize the data and import some extra libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "final-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "usual-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = sk.preprocessing.StandardScaler().fit_transform(features_train)\n",
    "features_validate = sk.preprocessing.StandardScaler().fit_transform(features_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-suspect",
   "metadata": {},
   "source": [
    "We need to normalize the data, because some classification calculation may end up not working properly if the the data has ranges that varies widely. normalizing will help us with that problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "interested-governor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(features_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "funny-consultancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 4 4 4 3 4 4 3 4 3 3 4 3 4 4 4 3 4 3 3 3 4 4 4 3 4 4 4 4 4 4 3 4\n",
      " 4 3 3 4 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 3 3 4 4 4 3 3 4 4 4 4 4 4 3 3 3 4\n",
      " 4 3 3 4 4 3 4 3 3 3 3 4 3 3 4 4 3 4 4 3 2 4 3 4 3 3 4 4 4 4 4 3 4 4 4 4 3\n",
      " 3 3 4 4 4 3 4 3 3 3 3 4 4 3 4 3 4 4 4 4 4 4 3 4 3 3 4 4 3 3 4 4 3 3 3 3 3\n",
      " 4 4 4 3 4 4 4 3 2 4 4 4 4 4 3 3 3 4 4 4 3 3 3 3 3 3 4 4 4 3 4 2 3 4 3 3 3\n",
      " 4 3 3 3 3 3 4 3 3 2 3 4 4 4 4 3 4 3 3 3 4 3 3 3 3 4 4 4 3 3 3 4 4 3 4 4 4\n",
      " 4 4 4 3 3 4 4 3 4 3 4 4 3 4 3 4 4 3 4 4 3 3 4 4 4 4 4 4 3 4 3 3 4 4 3 3 2\n",
      " 3 4 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "label_prediction = svc.predict(features_validate)\n",
    "print(label_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "central-column",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.80      0.20      0.32        20\n",
      "           3       0.59      0.64      0.62       115\n",
      "           4       0.63      0.72      0.67       119\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.61       267\n",
      "   macro avg       0.34      0.26      0.27       267\n",
      "weighted avg       0.59      0.61      0.59       267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_validate, label_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-driver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
